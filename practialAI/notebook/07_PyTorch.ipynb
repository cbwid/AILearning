{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbwid/practialAI/blob/main/notebook/07_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOChJSNXtC9g"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLIxEDq6VhvZ"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/logo.png\" width=150>\n",
        "\n",
        "在这节课中，我们将学习PyTorch，它是一个用于构建动态神经网络的学习库。我们将在本课程中了解其基础知识，以及如何创建和使用张量（Tensor），而我们将在下一课中使用它制作模型。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/GokuMohandas/practicalAI/master/images/pytorch.png\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoMq0eFRvugb"
      },
      "source": [
        "# Tensor 基础知识"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-dXQiLlTIgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a7cd9c-6f1a-4cdb-ede9-bf756d1a8aa7"
      },
      "source": [
        "# 安装PyTorch库\n",
        "!pip3 install torch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6z1cCPTZSwo"
      },
      "source": [
        ">  注意：上述安装PyTorch的方式与官网并不一致，因为这里是基于Colab云端安装的，而大家一般是使用pip或者conda来安装PyTorch。具体安装教程参考：https://pytorch.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX7Vs1JxL9wX"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-sPMPTMCDI9"
      },
      "source": [
        "**张量(Tensor)：**张量如同数组和矩阵一样，是一种特殊的数据结构，在pytorch中，神经网络的输入、输出以及网络的参数等数据，都是使用张量来进行描述的\n",
        "\n",
        "张量的使用和中numpy的ndarrays很类似，区别在于张量可以在gpu上或者其他专用硬件上运行，这样可以得到更快的加速效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv0xryLkKujV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef76956-7504-4d30-848c-475f59c3f30c"
      },
      "source": [
        "# 创建一个张量\n",
        "x = torch.Tensor(3, 4)\n",
        "print(\"Type: {}\".format(x.type()))\n",
        "print(\"Size: {}\".format(x.shape))\n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Size: torch.Size([3, 4])\n",
            "Values: \n",
            "tensor([[-3.6462e-38,  3.0756e-41,  3.7835e-44,  0.0000e+00],\n",
            "        [        nan,  3.0756e-41,  1.3733e-14,  6.4069e+02],\n",
            "        [ 4.3066e+21,  1.1824e+22,  4.3066e+21,  6.3828e+28]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnyzY4PHL7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90571df5-d182-4ba6-cf90-8f308c69fa3f"
      },
      "source": [
        "# 创建一个随机张量\n",
        "x = torch.randn(2, 3) # torch.randn对应于正态分布，而rand(2,3)对应于均匀分布\n",
        "print (x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0198,  2.1064, -2.1692],\n",
            "        [-0.3814,  0.0942,  0.5195]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVwGNeKxMXI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea114704-fa5f-4df0-b51a-047d9fe012ec"
      },
      "source": [
        "# 0和1张量\n",
        "x = torch.zeros(2, 3)\n",
        "print (x)\n",
        "x = torch.ones(2, 3)\n",
        "print (x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPjHnDmCMXLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe2897-566b-464b-eec9-84be4084f5f5"
      },
      "source": [
        "# 列表（List） → 张量\n",
        "x = torch.Tensor([[1, 2, 3],[4, 5, 6]])\n",
        "print(\"Size: {}\".format(x.shape)) \n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG4-CHkgMXOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b2f1e3-3a72-4b40-f7fb-08639d4640cd"
      },
      "source": [
        "# NumPy 数组 → 张量\n",
        "x = torch.from_numpy(np.random.rand(2, 3))\n",
        "print(\"Size: {}\".format(x.shape)) \n",
        "print(\"Values: \\n{}\".format(x))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[0.4976, 0.9920, 0.0452],\n",
            "        [0.0426, 0.3398, 0.2478]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCKaxQn4DTr-",
        "outputId": "47ca2f88-aacd-42d0-98f6-ccfd6a67188f"
      },
      "source": [
        "# 张量 → 数组\n",
        "t=torch.ones(5)\n",
        "print(f't:{t}')\n",
        "n=t.numpy()\n",
        "print(f'n:{n}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t:tensor([1., 1., 1., 1., 1.])\n",
            "n:[1. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxccN_37C83c"
      },
      "source": [
        "张量和Numpy array数组在CPU上可以公用一块内存区域，改变其中一个另一个也会随之改变"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfnnHxt4D5k0",
        "outputId": "0b3487da-24b1-46ce-8323-048dc020b2ea"
      },
      "source": [
        "# 修改张量的值\n",
        "t.add_(1)\n",
        "print(f't:{t}')\n",
        "print(f'n:{n}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t:tensor([2., 2., 2., 2., 2.])\n",
            "n:[2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clRcUOOLEJCn",
        "outputId": "5a2b3f2e-3094-4a20-a3b6-7cc3dc85008e"
      },
      "source": [
        "# 修改numpy array数组的值\n",
        "np.add(n,1,out=n)\n",
        "print(f't:{t}')\n",
        "print(f'n:{n}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t:tensor([3., 3., 3., 3., 3.])\n",
            "n:[3. 3. 3. 3. 3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8X2-5cqMXRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b919bfb8-a62b-430a-bad0-093b575722c8"
      },
      "source": [
        "# 改变张量类型（张量默认为float类型）\n",
        "x = torch.Tensor(3, 4)\n",
        "print(\"Type: {}\".format(x.type()))\n",
        "x = x.long()\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n",
            "Type: torch.LongTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2BRPaMvPbe3"
      },
      "source": [
        "# Tensor 运算"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrn8I76TMXT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04ae6509-6de4-49ec-921b-0c46c09933e8"
      },
      "source": [
        "# 加法 + \n",
        "x = torch.randn(2, 3)\n",
        "print('x.values:\\n{}'.format(x))\n",
        "y = torch.randn(2, 3)\n",
        "print('y.values:\\n{}'.format(y))\n",
        "\n",
        "z = x + y\n",
        "print(\"Size: {}\".format(z.shape)) \n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.values:\n",
            "tensor([[ 0.4581, -1.3014,  1.3333],\n",
            "        [ 1.0540, -0.3632, -0.9469]])\n",
            "y.values:\n",
            "tensor([[-1.9857,  0.1520,  1.0433],\n",
            "        [ 0.3477, -1.5842,  0.0878]])\n",
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[-1.5276, -1.1495,  2.3766],\n",
            "        [ 1.4017, -1.9474, -0.8590]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "157fC9WsMXWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c992327e-84e3-4fb5-82c1-6681e53a1899"
      },
      "source": [
        "# 向量点积:torch.mm\n",
        "x = torch.randn(2, 3)\n",
        "y = torch.randn(3, 2)\n",
        "z = torch.mm(x, y)\n",
        "print(\"Size: {}\".format(z.shape)) \n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 2])\n",
            "Values: \n",
            "tensor([[ 0.5134, -0.4282],\n",
            "        [-1.8734,  1.1644]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6316lAmMXZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52e5d2a-21d6-477f-dc56-08a51337c601"
      },
      "source": [
        "# 转置 torch.t()\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Size: {}\".format(x.shape)) \n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.t(x)\n",
        "print(\"Size: {}\".format(y.shape)) \n",
        "print(\"Values: \\n{}\".format(y))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3])\n",
            "Values: \n",
            "tensor([[-0.5080, -0.1279,  0.2345],\n",
            "        [ 1.4296,  0.5443,  0.1609]])\n",
            "Size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[-0.5080,  1.4296],\n",
            "        [-0.1279,  0.5443],\n",
            "        [ 0.2345,  0.1609]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCgDCOCjMXcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c91677-8f04-420d-8d58-3b746335ded9"
      },
      "source": [
        "# Reshape 重新修改张量的维数，要保证数据的个数不变\n",
        "z = x.view(3, 2)\n",
        "print(\"Size: {}\".format(z.shape)) \n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([3, 2])\n",
            "Values: \n",
            "tensor([[-0.5080, -0.1279],\n",
            "        [ 0.2345,  1.4296],\n",
            "        [ 0.5443,  0.1609]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3-6nGgvECH9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c90d6f9-691c-4916-ffca-555168b02ef5"
      },
      "source": [
        "# reshaping的危险（意外后果）\n",
        "x = torch.tensor([\n",
        "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
        "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
        "])\n",
        "print(\"Size: {}\".format(x.shape)) \n",
        "print(\"Values: \\n{}\\n\".format(x))\n",
        "a = x.view(x.size(0), -1)\n",
        "print(\"Size: {}\".format(a.shape)) \n",
        "print(\"Values: \\n{}\\n\".format(a))\n",
        "b = x.transpose(0,1).contiguous()\n",
        "print(\"Size: {}\".format(b.shape)) \n",
        "print(\"Values: \\n{}\\n\".format(b))\n",
        "c = b.view(b.size(0), -1)\n",
        "print(\"Size: {}\".format(c.shape)) \n",
        "print(\"Values: \\n{}\".format(c))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([2, 3, 4])\n",
            "Values: \n",
            "tensor([[[ 1,  1,  1,  1],\n",
            "         [ 2,  2,  2,  2],\n",
            "         [ 3,  3,  3,  3]],\n",
            "\n",
            "        [[10, 10, 10, 10],\n",
            "         [20, 20, 20, 20],\n",
            "         [30, 30, 30, 30]]])\n",
            "\n",
            "Size: torch.Size([2, 12])\n",
            "Values: \n",
            "tensor([[ 1,  1,  1,  1,  2,  2,  2,  2,  3,  3,  3,  3],\n",
            "        [10, 10, 10, 10, 20, 20, 20, 20, 30, 30, 30, 30]])\n",
            "\n",
            "Size: torch.Size([3, 2, 4])\n",
            "Values: \n",
            "tensor([[[ 1,  1,  1,  1],\n",
            "         [10, 10, 10, 10]],\n",
            "\n",
            "        [[ 2,  2,  2,  2],\n",
            "         [20, 20, 20, 20]],\n",
            "\n",
            "        [[ 3,  3,  3,  3],\n",
            "         [30, 30, 30, 30]]])\n",
            "\n",
            "Size: torch.Size([3, 8])\n",
            "Values: \n",
            "tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],\n",
            "        [ 2,  2,  2,  2, 20, 20, 20, 20],\n",
            "        [ 3,  3,  3,  3, 30, 30, 30, 30]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H9y8m8GHqF1"
      },
      "source": [
        "```\n",
        "x=x.view(batchsize,-1)\n",
        "```\n",
        "中batchsize指转换后有几行，而-1指在不告诉函数有多少列的情况下，根据元tensor数据和batchsize自动分配列数\n",
        "\n",
        "torch.transpose()是pytorch种的ndarray矩阵进行转置的操作\n",
        "\n",
        "**transpose（）一次只能在两个维度间进行转换**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRtG5LShMXew",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d84d6a5-3d55-4266-8cfd-82e718ceab70"
      },
      "source": [
        "# 维度操作\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.sum(x, dim=0) # 为每列添加各行叠加的值\n",
        "print(\"Values: \\n{}\".format(y))\n",
        "z = torch.sum(x, dim=1) # 为每行添加各列叠加的值\n",
        "print(\"Values: \\n{}\".format(z))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[-1.2452,  1.9658,  0.1848],\n",
            "        [-0.2633, -0.2246, -1.1903]])\n",
            "Values: \n",
            "tensor([-1.5085,  1.7412, -1.0055])\n",
            "Values: \n",
            "tensor([ 0.9054, -1.6782])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0ZV45PrYmw"
      },
      "source": [
        "# 索引，切片和级联"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM3UFrs0MXhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b9fd29-ba60-4c4d-9fc2-a7ec74118079"
      },
      "source": [
        "x = torch.randn(3, 4)\n",
        "print(\"x: \\n{}\".format(x))\n",
        "print (\"x[:1]: \\n{}\".format(x[:1]))\n",
        "print (\"x[:1, 1:3]: \\n{}\".format(x[:1, 1:3]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x: \n",
            "tensor([[ 0.0303,  0.5724,  1.2252,  2.8963],\n",
            "        [ 0.3207, -0.2938, -0.4594, -0.3912],\n",
            "        [-0.0600, -1.7827,  0.8529, -0.3764]])\n",
            "x[:1]: \n",
            "tensor([[0.0303, 0.5724, 1.2252, 2.8963]])\n",
            "x[:1, 1:3]: \n",
            "tensor([[0.5724, 1.2252]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tbpwGxcMXj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91a6c3da-f58d-4eac-b333-d7ef543cc0ff"
      },
      "source": [
        "# 选择维度索引\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "col_indices = torch.LongTensor([0, 2])\n",
        "chosen = torch.index_select(x, dim=1, index=col_indices) # 第0和第2列的值\n",
        "print(\"Values: \\n{}\".format(chosen)) \n",
        "row_indices = torch.LongTensor([0, 1])\n",
        "chosen = x[row_indices, col_indices] # 来自（0,0）和（2,1）的值\n",
        "print(\"Values: \\n{}\".format(chosen)) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[-1.8211, -0.8792, -0.3720],\n",
            "        [ 0.1816, -0.3371, -0.2989]])\n",
            "Values: \n",
            "tensor([[-1.8211, -0.3720],\n",
            "        [ 0.1816, -0.2989]])\n",
            "Values: \n",
            "tensor([-1.8211, -0.2989])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMeqSQtuMXmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6fe5c77-0d74-44c9-b51b-d5e5355b479e"
      },
      "source": [
        "# 级联 将两个张量拼接在一起\n",
        "x = torch.randn(2, 3)\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "y = torch.cat([x, x], dim=0) # 按行堆叠（dim = 1按列堆叠）\n",
        "print(\"Values: \\n{}\".format(y))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[ 0.7832, -0.1492, -1.1440],\n",
            "        [ 1.1207,  0.7086, -1.9062]])\n",
            "Values: \n",
            "tensor([[ 0.7832, -0.1492, -1.1440],\n",
            "        [ 1.1207,  0.7086, -1.9062],\n",
            "        [ 0.7832, -0.1492, -1.1440],\n",
            "        [ 1.1207,  0.7086, -1.9062]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqiDuIC-ByvO"
      },
      "source": [
        "# 梯度"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxpGB7-VL7fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f65545e7-6697-4905-f443-c1f6b3ae2714"
      },
      "source": [
        "# 带有gradient bookkeeping的张量\n",
        "# requires_grad：用于说明当前是否需要为这个张量计算梯度\n",
        "# 如果一个张量的requires_grad=True，并不意味着这个张量的梯度属性会一直被存储。\n",
        "# 只有当张量为叶子节点的时候，梯度财会一直保存在grad属性中，对于非叶子节点，在计算完叶子节点后就会被释放掉\n",
        "# backward：反向传播计算梯度\n",
        "x = torch.rand(3, 4, requires_grad=True)\n",
        "y = 3*x + 2\n",
        "z = y.mean()\n",
        "z.backward() # z是标量\n",
        "print(\"Values: \\n{}\".format(x))\n",
        "print(\"x.grad: \\n\", x.grad)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Values: \n",
            "tensor([[0.7468, 0.6508, 0.5351, 0.0567],\n",
            "        [0.2301, 0.9529, 0.9215, 0.2108],\n",
            "        [0.7477, 0.9642, 0.1991, 0.2112]], requires_grad=True)\n",
            "x.grad: \n",
            " tensor([[0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf7htaAMDcRV"
      },
      "source": [
        "* $ y = 3x + 2 $\n",
        "* $ z = \\sum{y}/N $\n",
        "* $ \\frac{\\partial(z)}{\\partial(x)} = \\frac{\\partial(z)}{\\partial(y)} \\frac{\\partial(z)}{\\partial(x)} = \\frac{1}{N} * 3 = \\frac{1}{12} * 3 = 0.25 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQwzEBsLeVgm"
      },
      "source": [
        "**叶子节点：不依赖其他tensor的tensor**\n",
        "在pytorch中，神经网络层的权值w的tensor均为叶子节点，自己定义的tensor，例如：a=torch,tensor([1,0])定义的节点是叶子节点。但如果出现b=a+1的情况，*b也为叶子节点*，原因是：单纯的从数值关系上来看，b确实依赖a，但是从pytorch来看，所有的计算都是为了反向求导，而a的requires_grad属性为False，不需要获得梯度，那么在反向传播的过程中也是‘无意义’的，因此b为叶子节点"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_a7_FLChC0v"
      },
      "source": [
        "# 属性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1WfSPoYhaP9",
        "outputId": "d9d19656-53ae-46f4-e904-4a5b8ef09daa"
      },
      "source": [
        "# 从张量属性我们可以得出张量的维数、数据类型以及他们所存储的设备（CPU或GPU）\n",
        "x=torch.rand(3,4)\n",
        "print(f\"Shape of tensor: {x.shape}\")\n",
        "print(f\"Datatype of tensor: {x.dtype}\")\n",
        "print(f\"Device tensor is stored on: {x.device}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQtpZh1YD-kz"
      },
      "source": [
        "# CUDA 张量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_C3en05L7iT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34cf729e-5486-4466-898a-fa4ec33cd977"
      },
      "source": [
        "# CUDA可用吗？\n",
        "print (torch.cuda.is_available())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za47KWEJ6en2"
      },
      "source": [
        "如果上面的代码返回False，那么请转到菜单栏上的`Runtime`→`Change runtime type`并在`Hardware accelerator`下选择`GPU`。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY2DdN3j6ZxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf583ca-831e-4615-812b-2ddf50f0000d"
      },
      "source": [
        "# 创建一个CPU版的0张量\n",
        "x = torch.Tensor(3, 4).to(\"cpu\")\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcmdTggzEFPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a218fdad-4ba6-41f1-87a8-2a16089f989b"
      },
      "source": [
        "# 创建一个CUDA版的0张量\n",
        "x = torch.Tensor(3, 4).to(\"cuda\")\n",
        "print(\"Type: {}\".format(x.type()))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type: torch.cuda.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD-JUbH4hgt7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}